{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Machine Learning in...\n",
    "~~5 Lines~~  ~~3 Lines~~ **ONE LINE** of Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = KMeans(6).fit_predict(StandardScaler().fit_transform(pd.read_csv('../data/processed/chr_final_2018.csv', index_col=0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues\n",
    "This is problematic for many reasons, including:\n",
    "* Code is not easy to read\n",
    "* Analysis is not reproducible (how did we get that CSV file?)\n",
    "* Have to retrain the model every time we want to make predictions\n",
    "* No way of understanding the significance of the clusters\n",
    "* No way of using the clusters in our business\n",
    "* And where did that 6 come from??\n",
    "* We also cheated by doing data ETL and cleaning outside of the notebook (which is most of the work according to the [80/20 rule](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/))\n",
    "\n",
    "So lets redo that in a more comprehensive, comprehensible, reproducible way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Load\n",
    "* Download [raw county health data](http://www.countyhealthrankings.org/sites/default/files/chr_measures_CSV_2018.csv) from \n",
    "and save in data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data \n",
    "sdoh = pd.read_csv('../data/raw/chr_measures_CSV_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdoh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run `python make_dataset.py` at command line from top level project directory to write to data/interim and data/processed\n",
    "* See README for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has all data, for reference (with mapped column names) before limiting columns and dropping na\n",
    "# Written from create_dataset.py script\n",
    "interim = pd.read_csv('../data/interim/chr_interim_2018.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final dataset\n",
    "# Includes only columns used in the final model, will be fed directly into scaling and clustering\n",
    "X = pd.read_csv('../data/processed/chr_final_2018.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(interim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3000+ counties and county equivalents, some are dropped due to missing data\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim[X.columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick scatterplot matrix\n",
    "sns.pairplot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale - zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Returned object is a numpy array, so put columns and index back to use dataframe features\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can run some basic sanity checks - means should all be close to zero\n",
    "X_scaled.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Deviations should all be one\n",
    "X_scaled.std(ddof=0)  # divisor is N-ddof, default is sample mean meaning ddof=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also check this automatically using assert - \n",
    "\n",
    "# Assert the absolute value of all means is less than machine epsilon (with factor of 10 wiggle room)\n",
    "assert (X_scaled.mean().abs() < 1e-15).all(), 'Means should be zero post standardization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Number of Clusters\n",
    "* Run k-means clustering for k=2 clusters to k=20 clusters  \n",
    "* Select final number of clusters using the [elbow method](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set)\n",
    "* We are using inertia (sum of squared distances to to closest cluster center) because sklearn includes it, can also use percent variance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN=2\n",
    "MAX=20\n",
    "sum_squared_distances = []\n",
    "\n",
    "for n_clusters in range(MIN,MAX):\n",
    "    clustering = KMeans(n_clusters=n_clusters)\n",
    "    clustering.fit(X_scaled)\n",
    "    sum_squared_distances.append(clustering.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice elbow at 6 clusters! Smaller one at 4\n",
    "_ = plt.plot(range(MIN, MAX), sum_squared_distances)\n",
    "_ = plt.xlabel('Number of Clusters k')\n",
    "_ = plt.ylabel('Sum of Squared Errors')\n",
    "# _ = plt.axvline(x=6, color='#696969', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Train final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the order of the clusters may be different each time you retrain the model -\n",
    "# another reason saving the model is important\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # Could use sklearn pipeline to put scaler and clustering into one step\n",
    "clustering = KMeans(n_clusters=6)\n",
    "clustering.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now load previously trained model - cluster order will change every time\n",
    "with open('../models/final_clustering.pkl', 'rb') as infile:\n",
    "    reloaded_model = pickle.load(infile)\n",
    "    \n",
    "clustering = reloaded_model['kmeans']\n",
    "scaler = reloaded_model['scaler']\n",
    "label_map = reloaded_model['label_map']\n",
    "    \n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# reloaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Cluster Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clustering.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.Series(predictions, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.loc['Davidson,TN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of counties in each cluster (note this is not percentage of the population!)\n",
    "(100*predictions.value_counts().loc[range(0,6)]/len(predictions)).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.DataFrame(clustering.cluster_centers_,\n",
    "                       columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_column_names = ['Income', 'Social Associations', 'Access to Exercise', 'Food Desert', 'Long Commute Alone', 'Percent Rural', 'Lack English Prof.']\n",
    "unscaled_cluster_centers = pd.DataFrame(scaler.inverse_transform(clustering.cluster_centers_), \n",
    "                                        columns=short_column_names)  # X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round for display\n",
    "unscaled_cluster_centers.round(pd.Series([0,1,2,2,2,2,3], index=unscaled_cluster_centers.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_names = ['Average Suburbia', 'Isolated Urbanites', 'Small Town USA', \n",
    "                 'Rural Challenges', 'Vulnerable Locations', 'Rural Relationships']\n",
    "label_map = {}\n",
    "\n",
    "for val in zip(ordered_names, range(len(ordered_names))):\n",
    "    label_map[val[1]] = val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_cluster_centers.index = ordered_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_cluster_centers.round(pd.Series([0,1,2,2,2,2,3], index=unscaled_cluster_centers.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.index = ordered_names\n",
    "fig, ax = plt.subplots(figsize=(8,8))  \n",
    "sns.heatmap(clusters, annot=unscaled_cluster_centers, ax=ax, cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Scatter Plot \n",
    "Using Principal Components To Project to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "output = pd.DataFrame(pca.fit_transform(X_scaled), \n",
    "                      columns=['First Prinicpal Component', 'Second Principal Component'],\n",
    "                     index=X.index)\n",
    "output['cluster'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pd.DataFrame(pca.components_, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First principal component\n",
    "components[components.loc[0, :].abs().sort_values(ascending=False).index].loc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second principal component\n",
    "components[components.loc[1, :].abs().sort_values(ascending=False).index].loc[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['Persona Name'] = output['cluster'].map(lambda x: ordered_names[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.loc['Davidson,TN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.loc['Dickson,TN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment height=7 line for nicer image with seaborn>=0.8\n",
    "sns.set(font_scale=1.3)\n",
    "lm = sns.lmplot(x='First Prinicpal Component', \n",
    "                y='Second Principal Component',\n",
    "                data=output, #.sample(1000),\n",
    "                hue='Persona Name',  # 'cluster'\n",
    "                fit_reg=False, \n",
    "                height=7,\n",
    "                scatter_kws={'s': 50},\n",
    "                legend=True)\n",
    "plt.title('Principle Component View of Data')\n",
    "\n",
    "axes = lm.axes[0,0]\n",
    "\n",
    "_ = axes.set_xlabel(r'More Urban + More Exercise Op. + Higher Income $\\longrightarrow$')\n",
    "_ = axes.set_ylabel(r'Better Commute + More Social Assoc. + Worse Food Desert $\\longrightarrow$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Save serialized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clustering = {\n",
    "    'scaler': scaler,\n",
    "    'kmeans': clustering,\n",
    "    'input_format': X.columns,\n",
    "    'label_map': label_map,\n",
    "    'notes': 'SDoH clustering model for Nashville Analytics Summit. Trained 7/2019 on 2018 County Health Ranking data'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clustering.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clustering['label_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/example.pkl', 'wb') as outfile:\n",
    "    pickle.dump(final_clustering, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example reload\n",
    "with open('../models/example.pkl', 'rb') as infile:\n",
    "    reloaded_model = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model['kmeans'].cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Use custom module/package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analytics_manager = src.models.analytics_manager.AnalyticsManager('../models/final_clustering.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.analytics_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(src.models.analytics_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics_manager = src.models.analytics_manager.AnalyticsManager(\n",
    "    '../models/final_clustering.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics_manager.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analytics_manager.write_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnalyticsManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ../src/models/analytics_manager.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnalyticsManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.models.analytics_manager import AnalyticsManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
